{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b2c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_26720\\3492019641.py:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>What Comes Next? Rockwell Reminds Us</td>\n",
       "      <td>People think they know Norman Rockwell, and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>This Woman Photographed Herself Every Time She...</td>\n",
       "      <td>Emily Knecht takes photos of herself pouting. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Polarize the 24/7 Hustle Mentality and Focus o...</td>\n",
       "      <td>So, if you're a big fan of Gary V or Grant Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>Billions Of Cicadas Are About To Rise From The...</td>\n",
       "      <td>Hope you like the sound of humming. That is, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Obama Photographer Baits Donald Trump With Jer...</td>\n",
       "      <td>Pete Souza,Â the White House photographer unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>Connecting The Misogyny Of The Internet To The...</td>\n",
       "      <td>\"It's about an understanding of the relationsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>WOMEN</td>\n",
       "      <td>Now A Company Is Using 'The Handmaid's Tale' T...</td>\n",
       "      <td>Well, this is a terrible idea. Sleepwear compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>ARTS &amp; CULTURE</td>\n",
       "      <td>Slashies vs. Yuccies: Real Faces of the New Cr...</td>\n",
       "      <td>Maybe you've heard the term \"slashie\" a creati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>WOMEN</td>\n",
       "      <td>Why We Shouldnât Ignore The Misogyny In Trum...</td>\n",
       "      <td>Trumpâs comments calling athletes like Colin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>TECH</td>\n",
       "      <td>Election Shock Popped The Progressive Bubble O...</td>\n",
       "      <td>Hillary ClintonâsÂ electionÂ lossÂ was like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category                                              title  \\\n",
       "495   ARTS & CULTURE               What Comes Next? Rockwell Reminds Us   \n",
       "658   ARTS & CULTURE  This Woman Photographed Herself Every Time She...   \n",
       "1467        BUSINESS  Polarize the 24/7 Hustle Mentality and Focus o...   \n",
       "5325         SCIENCE  Billions Of Cicadas Are About To Rise From The...   \n",
       "4460        POLITICS  Obama Photographer Baits Donald Trump With Jer...   \n",
       "946   ARTS & CULTURE  Connecting The Misogyny Of The Internet To The...   \n",
       "6409           WOMEN  Now A Company Is Using 'The Handmaid's Tale' T...   \n",
       "668   ARTS & CULTURE  Slashies vs. Yuccies: Real Faces of the New Cr...   \n",
       "6775           WOMEN  Why We Shouldnât Ignore The Misogyny In Trum...   \n",
       "6073            TECH  Election Shock Popped The Progressive Bubble O...   \n",
       "\n",
       "                                                   body  \n",
       "495   People think they know Norman Rockwell, and th...  \n",
       "658   Emily Knecht takes photos of herself pouting. ...  \n",
       "1467  So, if you're a big fan of Gary V or Grant Car...  \n",
       "5325  Hope you like the sound of humming. That is, i...  \n",
       "4460  Pete Souza,Â the White House photographer unde...  \n",
       "946   \"It's about an understanding of the relationsh...  \n",
       "6409  Well, this is a terrible idea. Sleepwear compa...  \n",
       "668   Maybe you've heard the term \"slashie\" a creati...  \n",
       "6775  Trumpâs comments calling athletes like Colin...  \n",
       "6073  Hillary ClintonâsÂ electionÂ lossÂ was like ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('news-article-categories.csv', encoding='latin-1')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6695348b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ARTS & CULTURE', 'BUSINESS', 'COMEDY', 'CRIME', 'EDUCATION',\n",
       "       'ENTERTAINMENT', 'ENVIRONMENT', 'MEDIA', 'POLITICS', 'RELIGION',\n",
       "       'SCIENCE', 'SPORTS', 'TECH', 'WOMEN'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcf9a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the categories\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data['category'] = label_encoder.fit_transform(data['category'])\n",
    "data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4851a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process text\n",
    "def text_process(text):\n",
    "    if isinstance(text, float) and np.isnan(text):\n",
    "        return \"\"\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Apply text processing to title and body\n",
    "data['title'] = data['title'].apply(text_process)\n",
    "data['body'] = data['body'].apply(text_process)\n",
    "\n",
    "# Combine title and body into a single feature\n",
    "data['combined_text'] = data['title'] + ' ' + data['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e13d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to vectors using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data['combined_text'])\n",
    "\n",
    "# Scale features using MinMaxScaler\n",
    "minmax_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = minmax_scaler.fit_transform(X_tfidf.toarray())\n",
    "\n",
    "# Combine scaled features with labels\n",
    "X_combined = np.column_stack((X_scaled, data['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30650be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_combined, data['category'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled[:, :-1],  # Features\n",
    "    X_resampled[:, -1],   # Labels\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Reshape input data for RNN\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5ee356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # Add this line to import TensorFlow\n",
    "\n",
    "# Define a custom callback to capture training history\n",
    "class TrainingHistoryCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for key, value in logs.items():\n",
    "            self.history[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b04fa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dirX\\rnn_tuning\\tuner0.json\n",
      "88/88 [==============================] - 1s 9ms/step\n",
      "Best Hyperparameters: {'units1': 128, 'activation1': 'relu', 'dropout1': 0.30000000000000004, 'num_rnn_layers': 3, 'units_rnn_0': 96, 'activation_rnn_0': 'relu', 'dropout_rnn_0': 0.30000000000000004, 'num_dense_layers': 1, 'units_dense_0': 48, 'activation_dense_0': 'relu', 'dropout_dense_0': 0.2, 'units_dense_1': 32, 'activation_dense_1': 'tanh', 'dropout_dense_1': 0.30000000000000004, 'units_dense_2': 48, 'activation_dense_2': 'tanh', 'dropout_dense_2': 0.2, 'units_rnn_1': 32, 'activation_rnn_1': 'tanh', 'dropout_rnn_1': 0.30000000000000004, 'units_rnn_2': 32, 'activation_rnn_2': 'relu', 'dropout_rnn_2': 0.2}\n",
      "Best Accuracy: 0.9493941553813258\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.80      0.88       205\n",
      "         1.0       0.92      0.92      0.92       204\n",
      "         2.0       0.95      0.96      0.95       212\n",
      "         3.0       0.97      0.99      0.98       196\n",
      "         4.0       0.91      1.00      0.95       207\n",
      "         5.0       0.92      0.98      0.95       204\n",
      "         6.0       0.98      0.98      0.98       202\n",
      "         7.0       0.96      0.94      0.95       200\n",
      "         8.0       0.96      0.96      0.96       232\n",
      "         9.0       0.96      0.99      0.97       206\n",
      "        10.0       0.96      0.96      0.96       170\n",
      "        11.0       0.95      0.99      0.97       184\n",
      "        12.0       0.93      0.96      0.94       176\n",
      "        13.0       0.95      0.89      0.92       208\n",
      "\n",
      "    accuracy                           0.95      2806\n",
      "   macro avg       0.95      0.95      0.95      2806\n",
      "weighted avg       0.95      0.95      0.95      2806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model-building function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add the first SimpleRNN layer\n",
    "    model.add(SimpleRNN(units=hp.Int('units1', min_value=32, max_value=128, step=32),\n",
    "                        input_shape=(1, X_train.shape[1]),\n",
    "                        activation=hp.Choice('activation1', values=['relu', 'tanh','sigmoid']),\n",
    "                        return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Add more SimpleRNN layers (you can customize the number and configuration)\n",
    "    for i in range(hp.Int('num_rnn_layers', min_value=1, max_value=3)):\n",
    "        model.add(SimpleRNN(units=hp.Int(f'units_rnn_{i}', min_value=32, max_value=128, step=32),\n",
    "                            activation=hp.Choice(f'activation_rnn_{i}', values=['relu', 'tanh','sigmoid']),\n",
    "                            return_sequences=True))\n",
    "        model.add(Dropout(hp.Float(f'dropout_rnn_{i}', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Flatten the output before Dense layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add Dense layers\n",
    "    for i in range(hp.Int('num_dense_layers', min_value=1, max_value=3)):\n",
    "        model.add(Dense(hp.Int(f'units_dense_{i}', min_value=16, max_value=64, step=16),\n",
    "                        activation=hp.Choice(f'activation_dense_{i}', values=['relu', 'tanh','sigmoid'])))\n",
    "        model.add(Dropout(hp.Float(f'dropout_dense_{i}', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Define the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # You can increase this value for a more comprehensive search\n",
    "    directory='my_dirX',\n",
    "    project_name='rnn_tuning'\n",
    ")\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "history_callback = TrainingHistoryCallback()\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_rnn, y_train_one_hot, epochs=50, validation_split=0.1, batch_size=32, callbacks=[early_stopping,history_callback])\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_one_hot = best_model.predict(X_test_rnn)\n",
    "y_pred = np.argmax(y_pred_one_hot, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best Hyperparameters:\", tuner.oracle.get_best_trials()[0].hyperparameters.values)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31104835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save TF-IDF Vectorizer\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "# Save MinMaxScaler\n",
    "joblib.dump(minmax_scaler, 'minmax_scaler.joblib')\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84047be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "Predicted Labels: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Function to process text\n",
    "def text_process(text):\n",
    "    if isinstance(text, float) and np.isnan(text):\n",
    "        return \"\"\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Load TF-IDF Vectorizer and MinMaxScaler\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.joblib')\n",
    "minmax_scaler = joblib.load('minmax_scaler.joblib')\n",
    "\n",
    "# Load the Best Model\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "# Sample new data (replace this with your new data)\n",
    "new_data = pd.DataFrame({\n",
    "    'title': ['Actor Jeff Hiller Talks â€œBright Colors And Bold Patternsâ€ and More (AUDIO)'],\n",
    "    'body' : ['This week I talked with actor Jeff Hiller about the hit Off Broadway play Bright Colors And Bold Patterns that heâ€™ll be joining on January 17th with a new opening night scheduled for February 4th. Hiller (Nightcap, 30 Rock & Broadwayâ€™s Bloody Bloody Andrew Jackson) will step into the starring role of this devastatingly funny hit play directed by Michael Urie (Torch Song, Buyer & Cellar, Ugly Betty) and written by Drew Droege the playâ€™s original star. Hiller will continue the playâ€™s triumphant Off Broadway run through February 25th at the SoHo Playhouse in NYC. Bright Colors And Bold Patterns is about Josh and Brennan who are about to get married in Palm Springs on a lovely Saturday afternoon. However, the night before becomes a drunken, drug-fueled riot because their friend Gerry arrives furious that their invitation says: â€œPlease refrain from wearing bright colors or bold patterns.â€ The play is produced by Zach Laks in association with Riki Kane Larimer and features set design by Dara Wishingrad. Tom DeTrinis serves as associate producer. Bright Colors And Bold Patterns was originally presented at VS Theatre in Los Angeles and directed by Molly Prather. I talked to Jeff about how thrilled he is to perform Drew Droegeâ€™s hysterical one man show and his spin on our LGBTQ issues. LISTEN: Â  When asked how he sees our LGBTQ community moving forward in this Trump administration Hiller stated: Jeff Hiller is a regular performer at the UCB Theatre in both New York City and Los Angeles. Jeff has also written and starred in a pilot for Universal Cable Productions as well as acting in pilots for NBC, Fox, and CBS. He will step in the role of Gerry in the hit Off Broadway playÂ Bright Colors And Bold PatternsÂ starting on January 17th at the SoHo Playhouse in NYC. For Info & Tix: brightcolorsandboldpatterns.com Listen to more LGBT Leaders, Allies & Celebrity Podcasts: OUTTAKE VOICESâ„¢ Download Podcasts on iTunes']\n",
    "})\n",
    "\n",
    "# Apply the same text processing as during training\n",
    "new_data['title'] = new_data['title'].apply(text_process)\n",
    "new_data['body'] = new_data['body'].apply(text_process)\n",
    "new_data['combined_text'] = new_data['title'] + ' ' + new_data['body']\n",
    "\n",
    "# Use the loaded TF-IDF Vectorizer and MinMaxScaler\n",
    "X_new_tfidf = tfidf_vectorizer.transform(new_data['body'])\n",
    "X_new_scaled = minmax_scaler.transform(X_new_tfidf.toarray())\n",
    "\n",
    "# Reshape input data for RNN\n",
    "X_new_rnn = X_new_scaled.reshape((X_new_scaled.shape[0], 1, X_new_scaled.shape[1]))\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "y_pred_one_hot = best_model.predict(X_new_rnn)\n",
    "y_pred = np.argmax(y_pred_one_hot, axis=1)\n",
    "\n",
    "# Now, y_pred contains the predicted labels for your new data\n",
    "print(\"Predicted Labels:\", y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
